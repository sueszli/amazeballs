{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preprocessing",
   "id": "1e2b24dde9ba9969"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "from preprocessing import *"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define vars",
   "id": "c44cf1c266c90570"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_size = 100\n",
    "seed = 42"
   ],
   "id": "27b0768d73b91c7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load data from either cached local files or remote files",
   "id": "cf12e62985a06e21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_all_data(sample_size):\n",
    "    # cache hit\n",
    "    cachepath = dataset_path / f\"cache_all_{sample_size}.csv\"\n",
    "    if cachepath.exists():\n",
    "        data = pd.read_csv(cachepath)\n",
    "        print(f\"total data size: {data.memory_usage(deep=True).sum() / 1e9:.2f} gb\")\n",
    "        return data\n",
    "\n",
    "    # cache miss\n",
    "    data = pd.DataFrame()\n",
    "    categories = get_all_categories()\n",
    "    for category in tqdm(categories, desc=\"loading all data\", ncols=100):\n",
    "        category_data = get_category_data(category, sample_size)\n",
    "        data = pd.concat([data, category_data], ignore_index=True)\n",
    "        tqdm.write(\n",
    "            f\"loaded {category} - category size: {category_data.memory_usage(deep=True).sum() / 1e9:.2f} gb, total size: {data.memory_usage(deep=True).sum() / 1e9:.2f} gb\")\n",
    "    data.to_csv(cachepath, index=False)\n",
    "    print(f\"total data size: {data.memory_usage(deep=True).sum() / 1e9:.2f} gb\")\n",
    "    return data"
   ],
   "id": "107cadef05de5d7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = get_all_data(sample_size=sample_size)",
   "id": "bbc879ac74c70fd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Preprocess by removing unnecessary columns\n",
    "Cleanup string columns.\n",
    "Remove nan rows.\n"
   ],
   "id": "53fae07dacddb22d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    df.drop(columns=[\"images\", \"asin\", \"parent_asin\", \"user_id\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
    "\n",
    "    df = df.dropna(subset=[\"text\", \"title\", \"rating\"])\n",
    "    df[\"text\"] = df[\"text\"].str.replace(r\"<.*?>\", \"\", regex=True)  # drop html tags\n",
    "    df[\"title\"] = df[\"title\"].str.replace(r\"<.*?>\", \"\", regex=True)\n",
    "    df[\"text\"] = df[\"text\"].str.strip()\n",
    "    df[\"title\"] = df[\"title\"].str.strip()\n",
    "    df = df[df[\"text\"].str.len() > 0]\n",
    "    df = df[df[\"title\"].str.len() > 0]\n",
    "    return df\n"
   ],
   "id": "f8b6a617e014d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = preprocess(df)",
   "id": "2f28e106084a71ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_inferences(df, sample_size):\n",
    "    results_path = dataset_path / f\"results_n{sample_size}.csv\"\n",
    "    print(f\"results_path: {results_path}\")\n",
    "    if not results_path.exists():\n",
    "        tqdm.pandas()\n",
    "\n",
    "        def process_row(row):\n",
    "            review = f\"{row['title']}: {row['text']}\"\n",
    "            sentiment, score = get_sentiment(review)\n",
    "            return {\n",
    "                \"language\": get_language(review),\n",
    "                \"sentiment\": sentiment,\n",
    "                \"sentiment_score\": score,\n",
    "                \"subjectivity_score\": get_subjectivity(review),\n",
    "                \"aspects\": get_aspects(review),\n",
    "                \"rating\": get_rating(review),\n",
    "            }\n",
    "\n",
    "        results = df.progress_apply(process_row, axis=1)\n",
    "        results.to_csv(results_path, index=False)\n",
    "    else:\n",
    "        results = pd.read_csv(results_path)\n",
    "\n",
    "    df = df.copy()\n",
    "    results = results[\"0\"].apply(lambda x: pd.Series(eval(x)))\n",
    "    results = results.rename(columns={\"rating\": \"predicted_rating\"})\n",
    "    df = pd.concat([df, results], axis=1)\n",
    "    return df"
   ],
   "id": "89d164a4088b83bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = add_inferences(df, sample_size=sample_size)\n",
    "df.head()"
   ],
   "id": "d09d94ee72cff249"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# save data\n",
    "df.to_csv(data_path / \"data.csv\", index=False)\n",
    "print(\"saved data\")"
   ],
   "id": "1a1be5e71ef18adf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
