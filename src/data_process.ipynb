{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Only for colab bc otherwise all the drive mapping etc gets super annoying."
      ],
      "metadata": {
        "id": "Qj48ei4e-lxO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raP4dVn1VnnO",
        "outputId": "d580698f-d923-4eb2-83fe-eaef1df817da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "# TODO fix requirements since pyzmq upgrade breaks colab\n",
        "#\n",
        "# This file is autogenerated by pip-compile with Python 3.11\n",
        "# by the following command:\n",
        "#\n",
        "#    pip-compile --output-file=requirements.txt requirements.in\n",
        "#\n",
        "accelerate==1.1.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   sentence-transformers\n",
        "aiohappyeyeballs==2.4.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "aiohttp==3.11.7\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   fsspec\n",
        "aiosignal==1.3.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "annotated-types==0.7.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pydantic\n",
        "appnope==0.1.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "asttokens==2.4.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   stack-data\n",
        "attrs==24.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "autocuda==0.16\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "autoflake==2.3.1\n",
        "    # via -r requirements.in\n",
        "bertopic==0.16.4\n",
        "    # via -r requirements.in\n",
        "blis==0.7.11\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   thinc\n",
        "boostaug==2.3.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "catalogue==2.0.10\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "    #   srsly\n",
        "    #   thinc\n",
        "certifi==2024.8.30\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   requests\n",
        "charset-normalizer==3.4.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   requests\n",
        "click==8.1.7\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "    #   nltk\n",
        "    #   typer\n",
        "    #   yake\n",
        "cloudpathlib==0.20.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   weasel\n",
        "comm==0.2.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "    #   ipywidgets\n",
        "confection==0.1.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   thinc\n",
        "    #   weasel\n",
        "contourpy==1.3.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   matplotlib\n",
        "cycler==0.12.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   matplotlib\n",
        "cymem==2.0.10\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   preshed\n",
        "    #   spacy\n",
        "    #   thinc\n",
        "datasets==3.1.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   evaluate\n",
        "    #   sentence-transformers\n",
        "    #   setfit\n",
        "debugpy==1.8.9\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "decorator==5.1.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipython\n",
        "dill==0.3.8\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   multiprocess\n",
        "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
        "    # via -r requirements.in\n",
        "et-xmlfile==2.0.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   openpyxl\n",
        "evaluate==0.4.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   setfit\n",
        "executing==2.1.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   stack-data\n",
        "filelock==3.16.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   huggingface-hub\n",
        "    #   torch\n",
        "    #   transformers\n",
        "findfile==2.0.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "    #   pyabsa\n",
        "fonttools==4.55.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   matplotlib\n",
        "frozenlist==1.5.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "    #   aiosignal\n",
        "fsspec[http]==2024.9.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   huggingface-hub\n",
        "    #   torch\n",
        "gitdb==4.0.11\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   gitpython\n",
        "gitpython==3.1.43\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "hdbscan==0.8.40\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "huggingface-hub==0.26.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   sentence-transformers\n",
        "    #   setfit\n",
        "    #   tokenizers\n",
        "    #   transformers\n",
        "idna==3.10\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   requests\n",
        "    #   yarl\n",
        "ipykernel==6.29.5\n",
        "    # via -r requirements.in\n",
        "ipython==8.29.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "    #   ipywidgets\n",
        "ipywidgets==8.1.5\n",
        "    # via -r requirements.in\n",
        "isort==5.13.2\n",
        "    # via -r requirements.in\n",
        "jedi==0.19.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipython\n",
        "jellyfish==1.1.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   yake\n",
        "jinja2==3.1.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "    #   torch\n",
        "joblib==1.4.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   hdbscan\n",
        "    #   nltk\n",
        "    #   pynndescent\n",
        "    #   scikit-learn\n",
        "jupyter-client==8.6.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "jupyter-core==5.7.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "    #   jupyter-client\n",
        "jupyterlab-widgets==3.0.13\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipywidgets\n",
        "kiwisolver==1.4.7\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   matplotlib\n",
        "langcodes==3.5.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "langdetect==1.0.9\n",
        "    # via -r requirements.in\n",
        "language-data==1.3.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   langcodes\n",
        "llvmlite==0.43.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   numba\n",
        "    #   pynndescent\n",
        "marisa-trie==1.2.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   language-data\n",
        "markdown-it-py==3.0.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   rich\n",
        "markupsafe==3.0.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   jinja2\n",
        "matplotlib==3.9.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "    #   plotnine\n",
        "    #   tikzplotlib\n",
        "matplotlib-inline==0.1.7\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "    #   ipython\n",
        "mdurl==0.1.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   markdown-it-py\n",
        "metric-visualizer==0.9.13.post1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "mizani==0.13.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   plotnine\n",
        "mpmath==1.3.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   sympy\n",
        "multidict==6.1.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "    #   yarl\n",
        "multiprocess==0.70.16\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "murmurhash==1.0.11\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   preshed\n",
        "    #   spacy\n",
        "    #   thinc\n",
        "natsort==8.4.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "nest-asyncio==1.6.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "networkx==3.4.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "    #   torch\n",
        "    #   yake\n",
        "nltk==3.9.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   textblob\n",
        "numba==0.60.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pynndescent\n",
        "    #   umap-learn\n",
        "numpy==1.26.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   bertopic\n",
        "    #   blis\n",
        "    #   contourpy\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   hdbscan\n",
        "    #   matplotlib\n",
        "    #   metric-visualizer\n",
        "    #   mizani\n",
        "    #   numba\n",
        "    #   pandas\n",
        "    #   patsy\n",
        "    #   plotnine\n",
        "    #   scikit-learn\n",
        "    #   scipy\n",
        "    #   seqeval\n",
        "    #   spacy\n",
        "    #   statsmodels\n",
        "    #   thinc\n",
        "    #   tikzplotlib\n",
        "    #   torchvision\n",
        "    #   transformers\n",
        "    #   umap-learn\n",
        "    #   yake\n",
        "openpyxl==3.1.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "packaging==24.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   huggingface-hub\n",
        "    #   ipykernel\n",
        "    #   matplotlib\n",
        "    #   plotly\n",
        "    #   setfit\n",
        "    #   spacy\n",
        "    #   statsmodels\n",
        "    #   thinc\n",
        "    #   transformers\n",
        "    #   weasel\n",
        "pandas==2.2.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   metric-visualizer\n",
        "    #   mizani\n",
        "    #   plotnine\n",
        "    #   pyabsa\n",
        "    #   statsmodels\n",
        "parso==0.8.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   jedi\n",
        "patsy==1.0.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   statsmodels\n",
        "pexpect==4.9.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipython\n",
        "pillow==11.0.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   matplotlib\n",
        "    #   sentence-transformers\n",
        "    #   tikzplotlib\n",
        "    #   torchvision\n",
        "platformdirs==4.3.6\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   jupyter-core\n",
        "plotly==5.24.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "plotnine==0.14.3\n",
        "    # via -r requirements.in\n",
        "preshed==3.0.9\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "    #   thinc\n",
        "prompt-toolkit==3.0.48\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipython\n",
        "propcache==0.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "    #   yarl\n",
        "protobuf==3.20.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "psutil==6.1.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   ipykernel\n",
        "ptyprocess==0.7.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pexpect\n",
        "pure-eval==0.2.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   stack-data\n",
        "pyabsa==2.4.1.post1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   boostaug\n",
        "pyarrow==18.1.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "pydantic==2.10.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   confection\n",
        "    #   spacy\n",
        "    #   thinc\n",
        "    #   weasel\n",
        "pydantic-core==2.27.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pydantic\n",
        "pyflakes==3.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   autoflake\n",
        "pygments==2.18.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipython\n",
        "    #   rich\n",
        "pynndescent==0.5.13\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   umap-learn\n",
        "pyparsing==3.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   matplotlib\n",
        "python-dateutil==2.9.0.post0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   jupyter-client\n",
        "    #   matplotlib\n",
        "    #   pandas\n",
        "pytorch-warmup==0.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "pytz==2024.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pandas\n",
        "pyyaml==6.0.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   datasets\n",
        "    #   huggingface-hub\n",
        "    #   transformers\n",
        "regex==2024.11.6\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   nltk\n",
        "    #   segtok\n",
        "    #   tiktoken\n",
        "    #   transformers\n",
        "requests==2.32.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   huggingface-hub\n",
        "    #   spacy\n",
        "    #   tiktoken\n",
        "    #   transformers\n",
        "    #   update-checker\n",
        "    #   weasel\n",
        "rich==13.9.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   typer\n",
        "ruff==0.8.0\n",
        "    # via -r requirements.in\n",
        "safetensors==0.4.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   transformers\n",
        "scikit-learn==1.5.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "    #   hdbscan\n",
        "    #   metric-visualizer\n",
        "    #   pynndescent\n",
        "    #   sentence-transformers\n",
        "    #   seqeval\n",
        "    #   setfit\n",
        "    #   umap-learn\n",
        "scipy==1.10.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   hdbscan\n",
        "    #   metric-visualizer\n",
        "    #   mizani\n",
        "    #   plotnine\n",
        "    #   pynndescent\n",
        "    #   scikit-learn\n",
        "    #   sentence-transformers\n",
        "    #   statsmodels\n",
        "    #   summa\n",
        "    #   umap-learn\n",
        "segtok==1.5.11\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   yake\n",
        "sentence-transformers[train]==3.3.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "    #   setfit\n",
        "sentencepiece==0.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "seqeval==1.2.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "setfit==1.1.0\n",
        "    # via -r requirements.in\n",
        "shellingham==1.5.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   typer\n",
        "six==1.16.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   asttokens\n",
        "    #   langdetect\n",
        "    #   python-dateutil\n",
        "smart-open==7.0.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   weasel\n",
        "smmap==5.0.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   gitdb\n",
        "spacy==3.7.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   en-core-web-sm\n",
        "    #   pyabsa\n",
        "spacy-legacy==3.0.12\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "spacy-loggers==1.0.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "srsly==2.4.8\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   confection\n",
        "    #   spacy\n",
        "    #   thinc\n",
        "    #   weasel\n",
        "stack-data==0.6.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipython\n",
        "statsmodels==0.14.4\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   plotnine\n",
        "summa==1.2.0\n",
        "    # via -r requirements.in\n",
        "sympy==1.13.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   torch\n",
        "tabulate==0.9.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "    #   yake\n",
        "tenacity==9.0.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   plotly\n",
        "termcolor==2.5.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   findfile\n",
        "    #   pyabsa\n",
        "textblob==0.18.0.post0\n",
        "    # via -r requirements.in\n",
        "thinc==8.2.5\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "threadpoolctl==3.5.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   scikit-learn\n",
        "tiktoken==0.8.0\n",
        "    # via -r requirements.in\n",
        "tikzplotlib==0.10.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "tokenizers==0.20.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   transformers\n",
        "torch==2.5.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   accelerate\n",
        "    #   pyabsa\n",
        "    #   pytorch-warmup\n",
        "    #   sentence-transformers\n",
        "    #   torchvision\n",
        "torchvision==0.20.1\n",
        "    # via -r requirements.in\n",
        "tornado==6.4.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipykernel\n",
        "    #   jupyter-client\n",
        "tqdm==4.67.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "    #   huggingface-hub\n",
        "    #   nltk\n",
        "    #   pyabsa\n",
        "    #   sentence-transformers\n",
        "    #   spacy\n",
        "    #   transformers\n",
        "    #   umap-learn\n",
        "traitlets==5.14.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   comm\n",
        "    #   ipykernel\n",
        "    #   ipython\n",
        "    #   ipywidgets\n",
        "    #   jupyter-client\n",
        "    #   jupyter-core\n",
        "    #   matplotlib-inline\n",
        "transformers==4.46.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pyabsa\n",
        "    #   sentence-transformers\n",
        "    #   setfit\n",
        "typer==0.13.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "    #   weasel\n",
        "typing-extensions==4.12.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   huggingface-hub\n",
        "    #   ipython\n",
        "    #   pyabsa\n",
        "    #   pydantic\n",
        "    #   pydantic-core\n",
        "    #   torch\n",
        "    #   typer\n",
        "tzdata==2024.2\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   pandas\n",
        "umap-learn==0.5.7\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   bertopic\n",
        "update-checker==0.18.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "    #   pyabsa\n",
        "urllib3==2.2.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   requests\n",
        "wasabi==1.1.3\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "    #   thinc\n",
        "    #   weasel\n",
        "wcwidth==0.2.13\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   prompt-toolkit\n",
        "weasel==0.4.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   spacy\n",
        "webcolors==24.11.1\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   tikzplotlib\n",
        "widgetsnbextension==4.0.13\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   ipywidgets\n",
        "wrapt==1.17.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   smart-open\n",
        "xlsxwriter==3.2.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   metric-visualizer\n",
        "xxhash==3.5.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   datasets\n",
        "    #   evaluate\n",
        "yake==0.4.8\n",
        "    # via -r requirements.in\n",
        "yarl==1.18.0\n",
        "    # via\n",
        "    #   -r requirements.in\n",
        "    #   aiohttp\n",
        "\n",
        "# The following packages are considered to be unsafe in a requirements file:\n",
        "# setuptools\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "_KqZQ4S_VxD0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_size = 1000\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "PQTpFO2F_X04"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zyRx38_pA8MO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import gc\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from contextlib import contextmanager\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "aFp6SEXbCBlF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_current_dir() -> Path:\n",
        "    try:\n",
        "        return Path(__file__).parent.absolute()\n",
        "    except NameError:\n",
        "        return Path(os.getcwd())\n",
        "\n",
        "\n",
        "if seed == -1:\n",
        "    seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # perf\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "    os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"  # (range: 16-512)\n",
        "\n",
        "\n",
        "\n",
        "data_path = get_current_dir() / \"data\"\n",
        "dataset_path = get_current_dir() / \"datasets\"\n",
        "weights_path = get_current_dir() / \"weights\"\n",
        "\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "os.makedirs(dataset_path, exist_ok=True)\n",
        "os.makedirs(weights_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "rX799tFW_XRV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question definition\n",
        " We chose task 21 from the list. Since these questions already cover a wide range of topics we did not modify them and took them as they were:\n",
        "\n",
        "\n",
        "\n",
        "1.   (RQ1) Are reviews for some categories of product on Amazon overall more positive than for other categories?\n",
        "2.   (RQ2) Are reviews more subjective for some classes of products than for others?\n",
        "3. (RQ3) Which aspects of different classes of products are the most important in the reviews?\n",
        "4. (RQ4) Can one predict the star rating from the review text?"
      ],
      "metadata": {
        "id": "nQZfCvghXjuY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Choose Dataset\n",
        "\n",
        "Now we went to look for data to answer all our questions. We found the Amazon Reviewsâ€™23 dataset which is a standarrd dataset in the RecSys and NLP community. It consists of 571.54M reviews with data from May 1996 to September 2023. It is also easily accessible through the Hugging Face library which made our lives much easier in data loading and preprocessing.  "
      ],
      "metadata": {
        "id": "Xli7NI-GV3mF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are caching dataset locally so we don't have to reload them all the time.\n",
        "Using datasets to download the set.\n",
        "After that we sample data with our given sample size and save it to cache it if needed"
      ],
      "metadata": {
        "id": "rxXgtSKz71Kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "def get_all_categories():\n",
        "\n",
        "\n",
        "    data = datasets.load_dataset(\"text\",\n",
        "                                 data_files=\"https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023/raw/main/all_categories.txt\",\n",
        "                                 streaming=False, cache_dir=dataset_path, trust_remote_code=True)\n",
        "    return data[\"train\"].to_dict()[\"text\"]\n",
        "\n",
        "def get_category_data(category, sample_size, seed):\n",
        "\n",
        "    # cache hit\n",
        "    cachepath = dataset_path / f\"cache_{category}_{sample_size}.csv\"\n",
        "    if cachepath.exists():\n",
        "        data = pd.read_csv(cachepath)\n",
        "        return data\n",
        "\n",
        "    # cache miss\n",
        "    data = datasets.load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", f\"raw_review_{category}\", streaming=True,\n",
        "                                 cache_dir=dataset_path, trust_remote_code=True)\n",
        "    sampled_data = []\n",
        "    for entry in tqdm(data[\"full\"].shuffle(seed=seed).take(sample_size), total=sample_size, desc=f\"sampling {category}\",\n",
        "                      ncols=100):\n",
        "        sampled_data.append(entry)\n",
        "    data = pd.DataFrame(sampled_data)\n",
        "    data[\"category\"] = category  # add category column\n",
        "    data.to_csv(cachepath, index=False)\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "Wx13zsKW7ywF"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again Caching, here we load the different sampled categories (sample-size rows per category) and push them to a complete csv"
      ],
      "metadata": {
        "id": "a5Le6Slc8fAU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BkDB2kJDdtr3"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# cache hit\n",
        "cachepath = dataset_path / f\"cache_all_{sample_size}.csv\"\n",
        "if cachepath.exists():\n",
        "    data = pd.read_csv(cachepath)\n",
        "    print(f\"total data size: {data.memory_usage(deep=True).sum() / 1e9:.2f} gb\")\n",
        "\n",
        "else:\n",
        "  # cache miss\n",
        "  data = pd.DataFrame()\n",
        "  categories = get_all_categories()\n",
        "  for category in tqdm(categories, desc=\"loading all data\", ncols=100):\n",
        "      category_data = get_category_data(category, sample_size,seed)\n",
        "      data = pd.concat([data, category_data], ignore_index=True)\n",
        "      tqdm.write(\n",
        "          f\"loaded {category} - category size: {category_data.memory_usage(deep=True).sum() / 1e9:.2f} gb, total size: {data.memory_usage(deep=True).sum() / 1e9:.2f} gb\")\n",
        "  data.to_csv(cachepath, index=False)\n",
        "  print(f\"total data size: {data.memory_usage(deep=True).sum() / 1e9:.2f} gb\")\n",
        "df = data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxQP9oHG7WuA",
        "outputId": "747eeb73-a0e9-45f0-d053-3e732e254364"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total data size: 0.03 gb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "FsscpYaf-cLh",
        "outputId": "36defdb3-946c-4028-a249-dcd4a27e85e5"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   rating                                              title  \\\n",
              "0     4.0                                               Soft   \n",
              "1     4.0  TRY THIS! test on FACE for match not hands, ev...   \n",
              "2     5.0                                  Excellent product   \n",
              "3     5.0                                         Five Stars   \n",
              "4     5.0                                Awesome foundation!   \n",
              "\n",
              "                                                text  \\\n",
              "0  I wear headbands like this in the evening when...   \n",
              "1  I first tried it on the back of my hand and wa...   \n",
              "2                   This is so very good for my hair   \n",
              "3          My daughter loves the foot pedicure unit.   \n",
              "4  I am so glad they made a product like this bec...   \n",
              "\n",
              "                                              images        asin parent_asin  \\\n",
              "0                                                 []  B082NKQ4ZT  B082NKQ4ZT   \n",
              "1  [{'small_image_url': 'https://images-na.ssl-im...  B08GSKRQKD  B08GSKRQKD   \n",
              "2                                                 []  B01DD1NOZU  B01DD1NOZU   \n",
              "3                                                 []  B01H1RGQGQ  B01H1RGQGQ   \n",
              "4  [{'small_image_url': 'https://images-na.ssl-im...  B07V9V5R48  B07V9V5R48   \n",
              "\n",
              "                        user_id      timestamp  helpful_vote  \\\n",
              "0  AHV6QCNBJNSGLATP56JAWJ3C4G2A  1583932042329             0   \n",
              "1  AF2BLE54TEMGZ546U763ZHZRXC4A  1612277896403             0   \n",
              "2  AHU2GG5RF6YAEWUFNLH3QH5RHDNQ  1637952741170             0   \n",
              "3  AGTR4A6CYH6AGEIYCAPYPQZERZLQ  1486999572000             0   \n",
              "4  AFV22L7AEKI2LW6HMLRLUKNYVBGQ  1568738284832             7   \n",
              "\n",
              "   verified_purchase    category  \n",
              "0              False  All_Beauty  \n",
              "1              False  All_Beauty  \n",
              "2               True  All_Beauty  \n",
              "3               True  All_Beauty  \n",
              "4               True  All_Beauty  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bb984bc-2d56-4f8a-8d1d-77afdaeae58d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>images</th>\n",
              "      <th>asin</th>\n",
              "      <th>parent_asin</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>helpful_vote</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Soft</td>\n",
              "      <td>I wear headbands like this in the evening when...</td>\n",
              "      <td>[]</td>\n",
              "      <td>B082NKQ4ZT</td>\n",
              "      <td>B082NKQ4ZT</td>\n",
              "      <td>AHV6QCNBJNSGLATP56JAWJ3C4G2A</td>\n",
              "      <td>1583932042329</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>All_Beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>TRY THIS! test on FACE for match not hands, ev...</td>\n",
              "      <td>I first tried it on the back of my hand and wa...</td>\n",
              "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
              "      <td>B08GSKRQKD</td>\n",
              "      <td>B08GSKRQKD</td>\n",
              "      <td>AF2BLE54TEMGZ546U763ZHZRXC4A</td>\n",
              "      <td>1612277896403</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>All_Beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Excellent product</td>\n",
              "      <td>This is so very good for my hair</td>\n",
              "      <td>[]</td>\n",
              "      <td>B01DD1NOZU</td>\n",
              "      <td>B01DD1NOZU</td>\n",
              "      <td>AHU2GG5RF6YAEWUFNLH3QH5RHDNQ</td>\n",
              "      <td>1637952741170</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>All_Beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Five Stars</td>\n",
              "      <td>My daughter loves the foot pedicure unit.</td>\n",
              "      <td>[]</td>\n",
              "      <td>B01H1RGQGQ</td>\n",
              "      <td>B01H1RGQGQ</td>\n",
              "      <td>AGTR4A6CYH6AGEIYCAPYPQZERZLQ</td>\n",
              "      <td>1486999572000</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>All_Beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>Awesome foundation!</td>\n",
              "      <td>I am so glad they made a product like this bec...</td>\n",
              "      <td>[{'small_image_url': 'https://images-na.ssl-im...</td>\n",
              "      <td>B07V9V5R48</td>\n",
              "      <td>B07V9V5R48</td>\n",
              "      <td>AFV22L7AEKI2LW6HMLRLUKNYVBGQ</td>\n",
              "      <td>1568738284832</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>All_Beauty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bb984bc-2d56-4f8a-8d1d-77afdaeae58d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bb984bc-2d56-4f8a-8d1d-77afdaeae58d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bb984bc-2d56-4f8a-8d1d-77afdaeae58d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-90d9fed9-3f40-461b-8ca3-b827ccef5e33\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90d9fed9-3f40-461b-8ca3-b827ccef5e33')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-90d9fed9-3f40-461b-8ca3-b827ccef5e33 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 34000,\n  \"fields\": [\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610313887375197,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.0,\n          1.0,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26268,\n        \"samples\": [\n          \"Purchased as a gift pantry item for a friend\",\n          \"Interesting early Debussy breaking out of Massenet mode\",\n          \"Easy to swallow\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32882,\n        \"samples\": [\n          \"These diapers are great. I got them to have here in the house when my 2 year old grandson was visiting. My daughter-in-law has been a Pampers user for all of her children, so I was afraid when she saw these she would not want to use them. However, surprisingly she did try them and to my surprise actually liked them. These are just as absorbent and fit my grandbaby as well as Pampers, and with one exception are comparable to their cruisers cousins. The price! Given that she now has three children, all different ages and at different stages of their training, these Amazon Brand are a great way for her to still 'pamper' her baby while saving much needed cash. After using them exclusively for the weekend, she asked me for the link of where to get these (so she could use them when she got home). I ended up buying her a pack and shipping it to her so it was there when she got home. But I know she is sold on these now and will most likely change to the Amazon brand when she goes for her next order.\",\n          \"I am an educator so this free download seemed great. Understand that this program is teaching a ball and stick, double stroke writing method that is not natural for young writers. You can still use the nice features but ignore the demo. All letters start at the top, and follow a smooth pattern in one stroke. If I try to offer suggestions, my rating won't be listed. Good luck.\",\n          \"This is always a reliable physical gift during the holidays! My friends enjoy this and love the reindeer that is attached to the gift box!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"images\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1971,\n        \"samples\": [\n          \"[{'small_image_url': 'https://m.media-amazon.com/images/I/614Ut3pVNPL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/614Ut3pVNPL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/614Ut3pVNPL._SL1600_.jpg', 'attachment_type': 'IMAGE'}, {'small_image_url': 'https://m.media-amazon.com/images/I/61DNEvABIBL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/61DNEvABIBL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/61DNEvABIBL._SL1600_.jpg', 'attachment_type': 'IMAGE'}, {'small_image_url': 'https://m.media-amazon.com/images/I/61O89+f9BYL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/61O89+f9BYL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/61O89+f9BYL._SL1600_.jpg', 'attachment_type': 'IMAGE'}]\",\n          \"[{'small_image_url': 'https://m.media-amazon.com/images/I/61S3DWhaVoL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/61S3DWhaVoL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/61S3DWhaVoL._SL1600_.jpg', 'attachment_type': 'IMAGE'}, {'small_image_url': 'https://m.media-amazon.com/images/I/61d2jTTM2UL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/61d2jTTM2UL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/61d2jTTM2UL._SL1600_.jpg', 'attachment_type': 'IMAGE'}, {'small_image_url': 'https://m.media-amazon.com/images/I/61moeWe8XvL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/61moeWe8XvL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/61moeWe8XvL._SL1600_.jpg', 'attachment_type': 'IMAGE'}, {'small_image_url': 'https://m.media-amazon.com/images/I/71JGzS-ngpL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/71JGzS-ngpL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/71JGzS-ngpL._SL1600_.jpg', 'attachment_type': 'IMAGE'}, {'small_image_url': 'https://m.media-amazon.com/images/I/71iZbHi7ixL._SL256_.jpg', 'medium_image_url': 'https://m.media-amazon.com/images/I/71iZbHi7ixL._SL800_.jpg', 'large_image_url': 'https://m.media-amazon.com/images/I/71iZbHi7ixL._SL1600_.jpg', 'attachment_type': 'IMAGE'}]\",\n          \"[{'small_image_url': 'https://images-na.ssl-images-amazon.com/images/I/81e0e06KxTL._SL256_.jpg', 'medium_image_url': 'https://images-na.ssl-images-amazon.com/images/I/81e0e06KxTL._SL800_.jpg', 'large_image_url': 'https://images-na.ssl-images-amazon.com/images/I/81e0e06KxTL.jpg', 'attachment_type': 'IMAGE'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31010,\n        \"samples\": [\n          \"B0052RDJ5Y\",\n          \"B08F9X2GLZ\",\n          \"B00TETXODI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parent_asin\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30406,\n        \"samples\": [\n          \"B0C68LVZZK\",\n          \"B0BN2MFT5H\",\n          \"B0051HEFAS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6462,\n        \"samples\": [\n          \"AHFLLZLXIWRHZIX2JCSUVNTFWUCQ\",\n          \"AHKOWV3W3KI4SKHLO3DC6FOI7SYA\",\n          \"AHAE6GIVSMB4B74IZYBWH5SATIFQ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 102946696815,\n        \"min\": 938204489000,\n        \"max\": 1679182693930,\n        \"num_unique_values\": 33996,\n        \"samples\": [\n          1552857732717,\n          1586729193943,\n          1610320826522\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"helpful_vote\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 0,\n        \"max\": 985,\n        \"num_unique_values\": 135,\n        \"samples\": [\n          63,\n          60,\n          131\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"verified_purchase\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true,\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 34,\n        \"samples\": [\n          \"Home_and_Kitchen\",\n          \"Video_Games\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Transformation (Preprocessing)"
      ],
      "metadata": {
        "id": "uQlzTHBMWIUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are dropping columns that are not interesting to us:\n",
        "\n",
        "\n",
        "\n",
        "*   asin: Product ID\n",
        "*   parent_asin: parentID of a product (different color / style etc. products have a parent)\n",
        "* user_id: Id of the reviewer\n",
        "* images: images that a user posts with the review\n",
        "\n",
        "\n",
        "Then we drop html tags in the text and title and strip leading and trailing whitespaces.\n",
        "Reviews with empty text and title are removed\n"
      ],
      "metadata": {
        "id": "G1HojScQ-XFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=[\"images\", \"asin\", \"parent_asin\", \"user_id\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\")\n",
        "\n",
        "df = df.dropna(subset=[\"text\", \"title\", \"rating\"])\n",
        "df[\"text\"] = df[\"text\"].str.replace(r\"<.*?>\", \"\", regex=True)  # drop html tags\n",
        "df[\"title\"] = df[\"title\"].str.replace(r\"<.*?>\", \"\", regex=True)\n",
        "df[\"text\"] = df[\"text\"].str.strip()\n",
        "df[\"title\"] = df[\"title\"].str.strip()\n",
        "df = df[df[\"text\"].str.len() > 0]\n",
        "df = df[df[\"title\"].str.len() > 0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXphdJPy8x5d",
        "outputId": "6531795f-4b04-4b2c-d974-b40921ecfb33"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-7d9a25737a77>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"text\"] = df[\"text\"].str.replace(r\"<.*?>\", \"\", regex=True)  # drop html tags\n",
            "<ipython-input-67-7d9a25737a77>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"title\"] = df[\"title\"].str.replace(r\"<.*?>\", \"\", regex=True)\n",
            "<ipython-input-67-7d9a25737a77>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"text\"] = df[\"text\"].str.strip()\n",
            "<ipython-input-67-7d9a25737a77>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"title\"] = df[\"title\"].str.strip()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Looking for answers\n",
        "\n",
        "\n",
        "To answer our questions we use different models.\n",
        "\n",
        "We want to analyze:\n",
        "\n",
        "\n",
        "*   Sentiment\n",
        "*   Subjectivity\n",
        "*   Aspects\n",
        "*   Rating prediction\n",
        "\n",
        "For this we use models from kaggle that may not yield SOTA results, but are managable to run for our on device analysis."
      ],
      "metadata": {
        "id": "c87GsJVSWnU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper methods\n",
        "\n",
        "def get_device(disable_mps=False) -> str:\n",
        "    if torch.backends.mps.is_available() and not disable_mps:\n",
        "        return \"mps\"\n",
        "    elif torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    else:\n",
        "        return \"cpu\"\n",
        "\n",
        "def print_gpu_memory() -> None:\n",
        "  if torch.cuda.is_available():\n",
        "    print(f\"memory summary: {torch.cuda.memory_summary(device='cuda')}\")\n",
        "    print(f\"gpu memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"gpu memory cached: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "    print(f\"gpu memory peak: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"gpu memory peak cached: {torch.cuda.max_memory_reserved() / 1e9:.2f} GB\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FC2636IqeOT-"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yake\n",
        "from langdetect import detect\n",
        "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "\n",
        "try:\n",
        "    device = get_device(disable_mps=False)\n",
        "except:\n",
        "    device = \"cpu\"\n",
        "print(f\"using device: {device}\")\n",
        "\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", device=device,\n",
        "                             model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
        "                             model_kwargs={\"cache_dir\": weights_path})\n",
        "\n",
        "subjectivity_pipeline = pipeline(task=\"text-classification\", model=\"cffl/bert-base-styleclassification-subjective-neutral\",\n",
        "                                top_k=None, device=device, model_kwargs={\"cache_dir\": weights_path})\n",
        "\n",
        "rating_tokenizer = AutoTokenizer.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\",\n",
        "                                                device=device, cache_dir=weights_path)\n",
        "rating_model = AutoModelForSequenceClassification.from_pretrained(\"LiYuan/amazon-review-sentiment-analysis\").to(device)\n",
        "\n",
        "kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, dedupLim=0.3, top=10, features=None)\n",
        "\n",
        "def process_row(row):\n",
        "    batch_size = len(batch)\n",
        "    review = f\"{row['title']}: {row['text']}\"\n",
        "    review = review[:512]  # Truncate once, at the beginning\n",
        "    try:\n",
        "        sentiment = sentiment_pipeline(review)[0]\n",
        "        sentiment_label = sentiment[\"label\"]\n",
        "        sentiment_score = sentiment[\"score\"]\n",
        "    except Exception as e:\n",
        "        print(\"error get_sentiment:\", e)\n",
        "        sentiment_label, sentiment_score = None, None\n",
        "\n",
        "    try:\n",
        "        subjectivity_score = subjectivity_pipeline(review)[0][0][\"score\"]\n",
        "    except Exception as e:\n",
        "        print(\"error get_subjectivity:\", e)\n",
        "        subjectivity_score = None\n",
        "\n",
        "    try:\n",
        "        keywords = kw_extractor.extract_keywords(review)\n",
        "        aspects = [kw for kw, score in keywords if score > 0.3]\n",
        "    except Exception as e:\n",
        "        print(\"error get_aspects:\", e)\n",
        "        aspects = None\n",
        "    try:\n",
        "        inputs = rating_tokenizer(review, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = rating_model(**inputs)\n",
        "        predicted_class_idx = outputs.logits.argmax().item()\n",
        "        predicted_class = rating_model.config.id2label[predicted_class_idx]\n",
        "        rating = float(predicted_class[0])\n",
        "    except Exception as e:\n",
        "        print(\"error get_rating:\", e)\n",
        "        rating = None\n",
        "\n",
        "    try:\n",
        "        language = detect(review)\n",
        "    except Exception as e:\n",
        "        print(\"error get_language:\", e)\n",
        "        language = None\n",
        "\n",
        "    return {\n",
        "        \"language\": language,\n",
        "        \"sentiment\": sentiment_label,\n",
        "        \"sentiment_score\": sentiment_score,\n",
        "        \"subjectivity_score\": subjectivity_score,\n",
        "        \"aspects\": aspects,\n",
        "        \"rating\": rating,\n",
        "    }\n",
        "\n",
        "results_path = dataset_path / f\"results_n{sample_size}.csv\"\n",
        "print(f\"results_path: {results_path}\")\n",
        "\n",
        "if not results_path.exists():\n",
        "    tqdm.pandas()\n",
        "    results = df.progress_apply(process_row, axis=1)\n",
        "    results.to_csv(results_path, index=False)\n",
        "else:\n",
        "    results = pd.read_csv(results_path)\n",
        "#only works on reload from csv?\n",
        "results = results[\"0\"].apply(lambda x: pd.Series(eval(x)))\n",
        "results = results.rename(columns={\"rating\": \"predicted_rating\"})\n",
        "df_results = pd.concat([df, results], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STNhRz-Ie-kr",
        "outputId": "cbc2bbe4-f0af-4dd9-c217-494423452b71"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n",
            "results_path: /content/datasets/results_n1000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.head()\n",
        "df_results.to_csv(data_path / \"data.csv\", index=False)\n",
        "print(\"saved data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld2qpd7LckXT",
        "outputId": "64907672-9dd3-47e2-b946-9011b58c6be9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What did we find"
      ],
      "metadata": {
        "id": "Cc_9UNJHWzFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data quality and difficulties"
      ],
      "metadata": {
        "id": "FGuQijqxWp9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What did we learn"
      ],
      "metadata": {
        "id": "A1CK9C2uW2SH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Who did what"
      ],
      "metadata": {
        "id": "x24To2HXW4V6"
      }
    }
  ]
}